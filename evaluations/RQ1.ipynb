{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05279818",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# RQ1: Comparison with Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27869a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../implementations/\")\n",
    "from classes.frameworks import Frameworks\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import dill\n",
    "import os\n",
    "import math\n",
    "frameworks = defaultdict(dict)\n",
    "memo_dir = \"./data/memo/\"\n",
    "muffin_dir = \"./data/muffin/\"\n",
    "lemon_dir = \"./data/lemon/\"\n",
    "cradle_dir = \"./data/cradle/\"\n",
    "all_experiments = {\n",
    "    \"memo\": memo_dir,\n",
    "    \"muffin\": muffin_dir,\n",
    "    \"lemon\": lemon_dir,\n",
    "    \"cradle\": cradle_dir\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f3513",
   "metadata": {},
   "source": [
    "# Get The Test Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141c6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class(home_dir, method):\n",
    "    backend = [\"tensorflow_new\"]\n",
    "    result_dict = {}\n",
    "    for bk in backend:\n",
    "        print(\"========= working on backend: {} ========\".format(bk))\n",
    "        file_path = os.path.join(home_dir, f\"{bk}.pkl\")\n",
    "        if method == \"cradle\":\n",
    "            file_path = os.path.join(home_dir, f\"{bk}_origin_models.pkl\")\n",
    "            \n",
    "        result_dict[bk] = dill.load(open(file_path, \"rb+\"))\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f46f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on method:  memo\n",
      "memo already exists, directly load the overall result\n",
      "working on method:  muffin\n",
      "muffin already exists, directly load the overall result\n",
      "working on method:  lemon\n",
      "lemon already exists, directly load the overall result\n",
      "working on method:  cradle\n",
      "cradle already exists, directly load the overall result\n"
     ]
    }
   ],
   "source": [
    "backend = [\"tensorflow_new\"]\n",
    "save_dir = \"./all_coverages\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "frameworks = defaultdict(dict)\n",
    "file_list = os.listdir(save_dir)\n",
    "frameworks = defaultdict(dict)\n",
    "\n",
    "for method in all_experiments:\n",
    "    print(\"working on method: \", method)\n",
    "    if f\"{method}_tensorflow_new.pkl\" in file_list:\n",
    "        print(f\"{method} already exists, directly load the overall result\")\n",
    "        for bk in backend:\n",
    "            frameworks[bk][method] = dill.load(open(os.path.join(save_dir, f\"{method}_{bk}.pkl\"), \"rb\"))\n",
    "    else:\n",
    "        result_dict = load_class(all_experiments[method], method)\n",
    "        for bk in backend:\n",
    "            print(\"working on backend: \", bk)\n",
    "            frameworks[bk][method] = result_dict[bk]\n",
    "            with open(os.path.join(save_dir, f\"{method}_{bk}.pkl\"), \"wb\") as file:\n",
    "                dill.dump(frameworks[bk][method], file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "034def9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on backend:  tensorflow_new\n",
      "\n",
      "---- working on method:  memo\n",
      "The coverage of module: API is:\n",
      "total_branch: 3024, hit_branch: 1198, coverage: 0.39616402116402116,                  total_line: 7487, coverage: 0.5709897155068786\n",
      "The coverage of module: Operators is:\n",
      "total_branch: 11308, hit_branch: 1008, coverage: 0.08914043155288291,                  total_line: 32562, coverage: 0.21322400343959216\n",
      "The coverage of module: Model is:\n",
      "total_branch: 2194, hit_branch: 941, coverage: 0.42889699179580676,                  total_line: 4961, coverage: 0.575488812739367\n",
      "Branch Coverage: 3147/16526(0.19042720561539392),               Line Coverage: 14073/45010(0.3126638524772273)\n",
      "\n",
      "---- working on method:  muffin\n",
      "The coverage of module: API is:\n",
      "total_branch: 3024, hit_branch: 1065, coverage: 0.3521825396825397,                  total_line: 7487, coverage: 0.5231735007346067\n",
      "The coverage of module: Operators is:\n",
      "total_branch: 11308, hit_branch: 755, coverage: 0.06676689069685178,                  total_line: 32562, coverage: 0.19547325102880658\n",
      "The coverage of module: Model is:\n",
      "total_branch: 2194, hit_branch: 840, coverage: 0.3828623518687329,                  total_line: 4961, coverage: 0.5394073775448498\n",
      "Branch Coverage: 2660/16526(0.1609584896526685),               Line Coverage: 12958/45010(0.2878915796489669)\n",
      "\n",
      "---- working on method:  lemon\n",
      "The coverage of module: API is:\n",
      "total_branch: 3024, hit_branch: 660, coverage: 0.21825396825396826,                  total_line: 7487, coverage: 0.3810605048751169\n",
      "The coverage of module: Operators is:\n",
      "total_branch: 11308, hit_branch: 536, coverage: 0.04740007074637425,                  total_line: 32562, coverage: 0.1803021927400037\n",
      "The coverage of module: Model is:\n",
      "total_branch: 2194, hit_branch: 795, coverage: 0.3623518687329079,                  total_line: 4961, coverage: 0.5234831687159847\n",
      "Branch Coverage: 1991/16526(0.12047682439791843),               Line Coverage: 11321/45010(0.251521884025772)\n",
      "\n",
      "---- working on method:  cradle\n",
      "The coverage of module: API is:\n",
      "total_branch: 3024, hit_branch: 628, coverage: 0.20767195767195767,                  total_line: 7487, coverage: 0.3659676773073327\n",
      "The coverage of module: Operators is:\n",
      "total_branch: 11308, hit_branch: 497, coverage: 0.04395118500176866,                  total_line: 32562, coverage: 0.17627909833548308\n",
      "The coverage of module: Model is:\n",
      "total_branch: 2194, hit_branch: 790, coverage: 0.3600729261622607,                  total_line: 4961, coverage: 0.5218705906067325\n",
      "Branch Coverage: 1915/16526(0.1158780104078422),               Line Coverage: 11069/45010(0.2459231281937347)\n"
     ]
    }
   ],
   "source": [
    "backends = [\"tensorflow_new\"]\n",
    "import json\n",
    "tensorflow_modules = json.load(open(\"../implementations/scripts/analysis/tensorflow_related_modules.json\", \"rb+\"))\n",
    "tensorflow_modules_meta = json.load(open(\"../implementations/scripts/analysis/tensorflow_modules_meta.json\", \"rb+\"))\n",
    "\n",
    "import os\n",
    "def search_within_files(file_keywards, files, cache):\n",
    "    for file in files:\n",
    "        dirname = os.path.dirname(file)\n",
    "        basename = os.path.basename(file)\n",
    "        if dirname not in tensorflow_modules:\n",
    "            continue\n",
    "        if basename not in tensorflow_modules[dirname]:\n",
    "            continue\n",
    "        if file_keywards not in file:\n",
    "            continue\n",
    "        for module in tensorflow_modules_meta:\n",
    "            if dirname in tensorflow_modules_meta[module]:\n",
    "                break\n",
    "        hit_line, total_line, hit_branch, total_branch = cache[module]\n",
    "        lt,lm,_,bh,bm,_ = files[file].coverage\n",
    "        hit_line += lt\n",
    "        total_line += lt+lm\n",
    "        hit_branch += bh\n",
    "        total_branch += bh+bm\n",
    "        cache[module] = (hit_line, total_line, hit_branch, total_branch)\n",
    "    return cache\n",
    "\n",
    "def ceil(x, decimal):\n",
    "    return math.ceil(x*10**decimal)/10**decimal\n",
    "\n",
    "for bk in backends:\n",
    "    print(\"working on backend: \", bk)\n",
    "    for method in frameworks[bk]:\n",
    "        cache = {}\n",
    "        print(\"\\n---- working on method: \", method)\n",
    "        hit_line, total_line, hit_branch, total_branch = 0,0,0,0\n",
    "        file_keywards = \".py\"\n",
    "        for module in tensorflow_modules_meta:\n",
    "            cache[module] = (hit_line, total_line, hit_branch, total_branch)\n",
    "        cache = search_within_files(file_keywards, frameworks[bk][method].c_files, cache)\n",
    "        cache = search_within_files(file_keywards, frameworks[bk][method].py_files, cache)\n",
    "        for module in cache:\n",
    "            print(f\"The coverage of module: {module} is:\")\n",
    "            hl, tl, hr, tr = cache[module]\n",
    "            hit_branch += hr\n",
    "            total_branch += tr\n",
    "            hit_line += hl\n",
    "            total_line += tl\n",
    "            print(f\"total_branch: {tr}, hit_branch: {hr}, coverage: {hr/tr},\\\n",
    "                  total_line: {tl}, coverage: {hl/tl}\")\n",
    "#         print(f\"Branch Coverage: {hit_branch}/{total_branch}({ceil(hit_branch/total_branch, 3)}), \\\n",
    "#               Line Coverage: {hit_line}/{total_line}({ceil(hit_line/total_line, 3)})\")\n",
    "        \n",
    "        print(f\"Branch Coverage: {hit_branch}/{total_branch}({hit_branch/total_branch}), \\\n",
    "              Line Coverage: {hit_line}/{total_line}({hit_line/total_line})\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a387f0",
   "metadata": {},
   "source": [
    "# Get the Coverage For Layer Call Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad77a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on method:  memo\n",
      "{'layer input coverage': '0.6971279373368147', 'layer parameter coverage': '0.5017081503172279', 'layer sequence coverage': '0.1884606816662954', 'layer api coverage': '1.0', 'layer input dimension coverage': '0.9401709401709402', 'layer input datatype coverage': '0.4774011299435028', 'layer input shape coverage': '0.864406779661017'}\n",
      "working on method:  muffin\n",
      "{'layer input coverage': '0.34073107049608353', 'layer parameter coverage': '0.25866276232308444', 'layer sequence coverage': '0.07529516596123859', 'layer api coverage': '0.6865671641791045', 'layer input dimension coverage': '0.41025641025641024', 'layer input datatype coverage': '0.10734463276836158', 'layer input shape coverage': '0.5932203389830508'}\n",
      "working on method:  lemon\n",
      "{'layer input coverage': '0.1422976501305483', 'layer parameter coverage': '0.06442166910688141', 'layer sequence coverage': '0.011806638449543327', 'layer api coverage': '0.29850746268656714', 'layer input dimension coverage': '0.18803418803418803', 'layer input datatype coverage': '0.05084745762711865', 'layer input shape coverage': '0.23389830508474577'}\n",
      "working on method:  cradle\n",
      "{'layer input coverage': '0.10443864229765012', 'layer parameter coverage': '0.05856515373352855', 'layer sequence coverage': '0.005569169079973268', 'layer api coverage': '0.208955223880597', 'layer input dimension coverage': '0.1111111111111111', 'layer input datatype coverage': '0.03389830508474576', 'layer input shape coverage': '0.1864406779661017'}\n"
     ]
    }
   ],
   "source": [
    "def load_cov(home_dir, method):\n",
    "    file_path = os.path.join(home_dir, f\"{bk}_api_cov.txt\")\n",
    "    result_dict = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read().split(\"\\n\")[-2]\n",
    "    content = content.split(\"; \")\n",
    "    result_dict[\"layer input coverage\"] = content[3]\n",
    "    result_dict[\"layer parameter coverage\"] = content[2]\n",
    "    result_dict[\"layer sequence coverage\"] = content[1]\n",
    "    result_dict[\"layer api coverage\"] = content[0]\n",
    "    result_dict[\"layer input dimension coverage\"] = content[4]\n",
    "    result_dict[\"layer input datatype coverage\"] = content[5]\n",
    "    result_dict[\"layer input shape coverage\"] = content[6]\n",
    "    print(result_dict)\n",
    "\n",
    "for method in all_experiments:\n",
    "    print(\"working on method: \", method)\n",
    "    load_cov(all_experiments[method], method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
